{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение рекомендательной системы content-based model на основе популярности "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](2023-10-01_13-50-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим мы получили задание построить рекомендательную систему на основе контента, где необходимо:\n",
    "\n",
    "* Для каждого продукта создать характеризующие его признаки.\n",
    "* Найти показатель близости между всеми продуктами.\n",
    "* Порекомендовать пользователю продукты, которые показывают наибольшую близость с теми продуктами, которые он высоко оценил."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем подобную рекомендательную систему на практике. Будем работать с [датасетом](https://github.com/Lidiya-cutie/Mini_project_model_Netflix/blob/master/netflix_titles.zip), содержащим информацию об оценивании фильмов на платформе Netflix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки в данных:\n",
    "\n",
    "* *show_id* — id фильма,\n",
    "* *type* — его тип (фильм или сериал),\n",
    "* *title* — название,\n",
    "* *director* — режиссер,\n",
    "* *cast* — актерский состав,\n",
    "* *country* — страна,\n",
    "* *date_added* — дата добавления,\n",
    "* *release_year* — год выхода на экраны,\n",
    "* *rating* — рейтинг,\n",
    "* *duration* — продолжительность,\n",
    "* *listened_in* — жанр(-ы),\n",
    "* *description* — описание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_csv('netflix_titles.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь нам необходимо определить, на основании чего мы будем рассматривать близость фильмов. Выберем для этой задачи описание фильма, ведь в нём, скорее всего, содержится много информации. Однако описание — это текст. Есть много подходов к преобразованию текста в вектор, и мы будем использовать подход **TF-IDF** (*Term Frequency-Inverse Document Frequency*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Показатель TD-IDF** — это индикатор того, насколько релевантно слово в контексте документа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Его можно определить следующим образом:\n",
    "\n",
    "$$TF-IDF(слова) = TF(слова) * IDF(слова), \\ где:$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bullet \\ TF \\ слова = {{Количество \\ раз, \\ когда \\ слово \\ встретилось \\ в \\ тексте}\\over{Количество \\ всех \\ слов \\ в \\ тексте}};$\n",
    "\n",
    "$\\bullet \\ IDF \\ слова = log({{Общее \\ кол-во \\ документов}\\over{Кол-во \\ документов, \\ в \\ которых \\ встречается \\ слово}}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот показатель возрастает пропорционально количеству раз, когда слово встречается в тексте, и уменьшается пропорционально количеству слов во всех текстах в целом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом:\n",
    "\n",
    "$\\bullet$ **Коэффициент будет выше**, если слово характерно именно для этого текста, то есть встречается в данном тексте часто, но не встречается в других текстах.\n",
    "\n",
    "$\\bullet$ **Коэффициент будет ниже**, если слово не встречается почти нигде или встречается одинаковое количество раз во всех текстах, то есть не характеризует никакой текст в отдельности.\n",
    "\n",
    "Если интересно подробнее изучить алгоритм создания такого представления, можно прочитать эту [статью](https://medium.com/analytics-vidhya/tf-idf-term-frequency-technique-easiest-explanation-for-text-classification-in-nlp-with-code-8ca3912e58c3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы преобразовать текст по этому принципу, нам понадобится соответствующая **функция из библиотеки sklearn** — импортируем её:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее учтём **стоп-слова**, т.е. предлоги и другие служебные части речи, которые не несут содержательной информации, и с учётом этого определим нашу модель:\n",
    "\n",
    "```python\n",
    "model = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски пустыми строками:\n",
    "\n",
    "```python\n",
    "df['description'] = df['description'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформируем наши описания в матрицу:\n",
    "\n",
    "```python\n",
    "feature_matrix = model.fit_transform(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число столбцов в получившейся матрице 17905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "netflix_df['description'] = netflix_df['description'].fillna('')\n",
    "\n",
    "feature_matrix = model.fit_transform(netflix_df['description'])\n",
    "print(f'Число столбцов в получившейся матрице {feature_matrix.shape[1]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вычислим косинусную близость. Можно сделать это так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы используем здесь *linear_kernel()*, а не [cosine_similarity()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn.metrics.pairwise.cosine_similarity), так как в косинусном расстоянии в знаменателе реализуется нормировка векторов, а TF-IDF создаёт уже нормализованные векторы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернём индексацию и уберём дубликаты из данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(netflix_df.index,index=netflix_df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пропишем функцию для создания рекомендаций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores =   scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return netflix_df['title'].iloc[ind_movie]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, если мы хотим найти рекомендации по фильму \"Star Trek\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5788             Star Trek: The Next Generation\n",
       "5787                      Star Trek: Enterprise\n",
       "5786                 Star Trek: Deep Space Nine\n",
       "5557                     She's Out of My League\n",
       "134                                  7 Days Out\n",
       "6664                        The Midnight Gospel\n",
       "6023                                     Teresa\n",
       "4863    Pinkfong & Baby Shark's Space Adventure\n",
       "5104                                       Rats\n",
       "5970                             Tales by Light\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Star Trek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдём вторую рекомендацию для детского фильма \"Balto\", вышедшего на экраны в 1995 году:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vroomiz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Balto').iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* мы можем использовать фильтрацию по контенту, чтобы создавать рекомендации из аналогичных элементов;\n",
    "* у нас получилось рекомендовать пользователю продукты, которые показывают наибольшую близость с теми продуктами, которые он высоко оценил;\n",
    "* мы не сможем порекомендовать продукты другого жанра или контента, если он сам не отметит подобные фильмы как понравившиеся."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
